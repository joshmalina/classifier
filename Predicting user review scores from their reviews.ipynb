{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/joshuamalina/Downloads/reviews_Movies_and_TV_5.json.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>overall</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice L. Larson \"alice-loves-books\"</td>\n",
       "      <td>This is a charming version of the classic Dick...</td>\n",
       "      <td>good version of a classic</td>\n",
       "      <td>1203984000</td>\n",
       "      <td>ADZPIG9QOCDG5</td>\n",
       "      <td>02 26, 2008</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amarah Strack</td>\n",
       "      <td>It was good but not as emotionally moving as t...</td>\n",
       "      <td>Good but not as moving</td>\n",
       "      <td>1388361600</td>\n",
       "      <td>A35947ZP82G7JH</td>\n",
       "      <td>12 30, 2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Don't get me wrong, Winkler is a wonderful cha...</td>\n",
       "      <td>Winkler's Performance was ok at best!</td>\n",
       "      <td>1388361600</td>\n",
       "      <td>A3UORV8A9D5L2E</td>\n",
       "      <td>12 30, 2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Customer \"Softmill\"</td>\n",
       "      <td>Henry Winkler is very good in this twist on th...</td>\n",
       "      <td>It's an enjoyable twist on the classic story</td>\n",
       "      <td>1202860800</td>\n",
       "      <td>A1VKW06X1O2X7V</td>\n",
       "      <td>02 13, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BABE</td>\n",
       "      <td>This is one of the best Scrooge movies out.  H...</td>\n",
       "      <td>Best Scrooge yet</td>\n",
       "      <td>1387670400</td>\n",
       "      <td>A3R27T4HADWFFJ</td>\n",
       "      <td>12 22, 2013</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          reviewerName  \\\n",
       "0  Alice L. Larson \"alice-loves-books\"   \n",
       "1                        Amarah Strack   \n",
       "2                      Amazon Customer   \n",
       "3           Amazon Customer \"Softmill\"   \n",
       "4                                 BABE   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  This is a charming version of the classic Dick...   \n",
       "1  It was good but not as emotionally moving as t...   \n",
       "2  Don't get me wrong, Winkler is a wonderful cha...   \n",
       "3  Henry Winkler is very good in this twist on th...   \n",
       "4  This is one of the best Scrooge movies out.  H...   \n",
       "\n",
       "                                        summary  unixReviewTime  \\\n",
       "0                     good version of a classic      1203984000   \n",
       "1                        Good but not as moving      1388361600   \n",
       "2         Winkler's Performance was ok at best!      1388361600   \n",
       "3  It's an enjoyable twist on the classic story      1202860800   \n",
       "4                              Best Scrooge yet      1387670400   \n",
       "\n",
       "       reviewerID   reviewTime  overall        asin helpful  \n",
       "0   ADZPIG9QOCDG5  02 26, 2008      4.0  0005019281  [0, 0]  \n",
       "1  A35947ZP82G7JH  12 30, 2013      3.0  0005019281  [0, 0]  \n",
       "2  A3UORV8A9D5L2E  12 30, 2013      3.0  0005019281  [0, 0]  \n",
       "3  A1VKW06X1O2X7V  02 13, 2008      5.0  0005019281  [0, 0]  \n",
       "4  A3R27T4HADWFFJ  12 22, 2013      4.0  0005019281  [0, 0]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pretrained fast text model plus a discrete classifier (i.e. not regression) to see how well we perform in an 80 / 20 split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should it matter if we do cross validation or just a simple randomized, 80/20 split? What characteristics of the data set would have us favor one form of validation over the other? Perhaps we would do more cross validation if the distribution of our \"overall\" scores were not represented in each category? And thus our data set would be imbalanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we need to control for the size of our reviews? Is there a signal in its length? If we compress all the reviews to the same 50 / 100 / 300 dimensional vector size, might we be losing a signal? Should we add in another bit that stands for length of the review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about sentiment? Will that be captured by our fast text embedding? We should try on both a pretrained model and one that we train ourselves. Then we should also try to include some sentiment bit (average sentiment vs num pos words vs num negative words) and see if that increases our accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are probably a bunch of different ways of calculating sentiment. Maybe we try a few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the method of creating word embeddings / creating sentence embeddings affect classification accuracy? Why would it or wouldn't it? Maybe we can try gensim also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are neural nets more or less affected by skewed targets? forest based models are said to be pretty robust to variability. we'll try xgboost to see what our performance is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.697533e+06\n",
       "mean     4.110648e+00\n",
       "std      1.197615e+00\n",
       "min      1.000000e+00\n",
       "25%      4.000000e+00\n",
       "50%      5.000000e+00\n",
       "75%      5.000000e+00\n",
       "max      5.000000e+00\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of \"overall\" scores in the dataset\n",
    "df['overall'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x151db3160>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x151c136a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# well the data is definetly skewed toward meing more positive -- \n",
    "# will this affect training? will we have to down sample / upsample\n",
    "# the targets that are overly / not well represented?\n",
    "df.boxplot(column='overall', return_type='axes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets figure out if there is any signal coming from the length of the post\n",
    "df['reviewLength'] = df.apply(lambda x: len(x['reviewText']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewLength</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>251</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>236</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>760</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>207</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>135</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>107</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>432</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>102</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>124</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>601</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>205</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>213</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>116</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>137</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>113</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>295</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>156</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>261</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1070</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>464</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>322</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>295</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>104</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>333</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>234</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697503</th>\n",
       "      <td>1362</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697504</th>\n",
       "      <td>1041</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697505</th>\n",
       "      <td>2314</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697506</th>\n",
       "      <td>902</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697507</th>\n",
       "      <td>559</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697508</th>\n",
       "      <td>1172</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697509</th>\n",
       "      <td>2612</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697510</th>\n",
       "      <td>115</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697511</th>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697512</th>\n",
       "      <td>1265</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697513</th>\n",
       "      <td>2138</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697514</th>\n",
       "      <td>2570</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697515</th>\n",
       "      <td>1820</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697516</th>\n",
       "      <td>1014</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697517</th>\n",
       "      <td>2594</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697518</th>\n",
       "      <td>2184</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697519</th>\n",
       "      <td>645</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697520</th>\n",
       "      <td>4252</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697521</th>\n",
       "      <td>1342</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697522</th>\n",
       "      <td>2214</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697523</th>\n",
       "      <td>464</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697524</th>\n",
       "      <td>171</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697525</th>\n",
       "      <td>309</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697526</th>\n",
       "      <td>244</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697527</th>\n",
       "      <td>7187</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697528</th>\n",
       "      <td>474</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697529</th>\n",
       "      <td>769</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697530</th>\n",
       "      <td>538</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697531</th>\n",
       "      <td>266</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697532</th>\n",
       "      <td>1642</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1697533 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reviewLength  overall\n",
       "0                 299      4.0\n",
       "1                 122      3.0\n",
       "2                 251      3.0\n",
       "3                 153      5.0\n",
       "4                 148      4.0\n",
       "5                 236      5.0\n",
       "6                 760      5.0\n",
       "7                 207      5.0\n",
       "8                 135      5.0\n",
       "9                 107      5.0\n",
       "10                432      5.0\n",
       "11                102      5.0\n",
       "12                124      3.0\n",
       "13                601      5.0\n",
       "14                205      4.0\n",
       "15                213      5.0\n",
       "16                116      5.0\n",
       "17                137      4.0\n",
       "18                113      5.0\n",
       "19                295      5.0\n",
       "20                156      2.0\n",
       "21                261      5.0\n",
       "22               1070      5.0\n",
       "23                464      5.0\n",
       "24                316      5.0\n",
       "25                322      5.0\n",
       "26                295      4.0\n",
       "27                104      5.0\n",
       "28                333      5.0\n",
       "29                234      4.0\n",
       "...               ...      ...\n",
       "1697503          1362      5.0\n",
       "1697504          1041      5.0\n",
       "1697505          2314      5.0\n",
       "1697506           902      5.0\n",
       "1697507           559      5.0\n",
       "1697508          1172      3.0\n",
       "1697509          2612      5.0\n",
       "1697510           115      5.0\n",
       "1697511           200      5.0\n",
       "1697512          1265      5.0\n",
       "1697513          2138      3.0\n",
       "1697514          2570      4.0\n",
       "1697515          1820      2.0\n",
       "1697516          1014      4.0\n",
       "1697517          2594      1.0\n",
       "1697518          2184      1.0\n",
       "1697519           645      4.0\n",
       "1697520          4252      2.0\n",
       "1697521          1342      4.0\n",
       "1697522          2214      5.0\n",
       "1697523           464      5.0\n",
       "1697524           171      4.0\n",
       "1697525           309      3.0\n",
       "1697526           244      4.0\n",
       "1697527          7187      5.0\n",
       "1697528           474      1.0\n",
       "1697529           769      5.0\n",
       "1697530           538      5.0\n",
       "1697531           266      5.0\n",
       "1697532          1642      5.0\n",
       "\n",
       "[1697533 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['reviewLength', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewLength</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reviewLength</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.076519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>-0.076519</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewLength   overall\n",
       "reviewLength      1.000000 -0.076519\n",
       "overall          -0.076519  1.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so there is a slight negative correlation between review length and score?\n",
    "# so, as a review gets longer, it might get more negative, but the effect is not very strong\n",
    "df[['reviewLength', 'overall']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15d649cc0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9YH47cEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13b1c2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['reviewLength', 'overall']].iloc[0:100000].plot.scatter(x='reviewLength', y='overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13c008518>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIZ/x8iTkqhHU3bywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c1a5d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df['reviewLength'] > 2000][['reviewLength', 'overall']].iloc[0:100000].plot.scatter(x='reviewLength', y='overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    499343.000000\n",
       "mean       2259.295108\n",
       "std        1482.053648\n",
       "min        1001.000000\n",
       "25%        1319.000000\n",
       "50%        1801.000000\n",
       "75%        2684.000000\n",
       "max       32766.000000\n",
       "Name: reviewLength, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['reviewLength'] > 1000]['reviewLength'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anyway, it seems like the hit you take from being long doesnt have a huge effect. so we won't worry about it too much. but we will add a bit at some point to see if length has any effect on the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "might also be worth binning the lengths and looking at the average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697533"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows = df.shape[0]\n",
    "nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 of 1697533\n",
      "20000 of 1697533\n",
      "30000 of 1697533\n",
      "40000 of 1697533\n",
      "50000 of 1697533\n",
      "60000 of 1697533\n",
      "70000 of 1697533\n",
      "80000 of 1697533\n",
      "90000 of 1697533\n",
      "100000 of 1697533\n",
      "110000 of 1697533\n",
      "120000 of 1697533\n",
      "130000 of 1697533\n",
      "140000 of 1697533\n",
      "150000 of 1697533\n",
      "160000 of 1697533\n",
      "170000 of 1697533\n",
      "180000 of 1697533\n",
      "190000 of 1697533\n",
      "200000 of 1697533\n",
      "210000 of 1697533\n",
      "220000 of 1697533\n",
      "230000 of 1697533\n",
      "240000 of 1697533\n",
      "250000 of 1697533\n",
      "260000 of 1697533\n",
      "270000 of 1697533\n",
      "280000 of 1697533\n",
      "290000 of 1697533\n",
      "300000 of 1697533\n",
      "310000 of 1697533\n",
      "320000 of 1697533\n",
      "330000 of 1697533\n",
      "340000 of 1697533\n",
      "350000 of 1697533\n",
      "360000 of 1697533\n",
      "370000 of 1697533\n",
      "380000 of 1697533\n",
      "390000 of 1697533\n",
      "400000 of 1697533\n",
      "410000 of 1697533\n",
      "420000 of 1697533\n",
      "430000 of 1697533\n",
      "440000 of 1697533\n",
      "450000 of 1697533\n",
      "460000 of 1697533\n",
      "470000 of 1697533\n",
      "480000 of 1697533\n",
      "490000 of 1697533\n",
      "500000 of 1697533\n",
      "510000 of 1697533\n",
      "520000 of 1697533\n",
      "530000 of 1697533\n",
      "540000 of 1697533\n",
      "550000 of 1697533\n",
      "560000 of 1697533\n",
      "570000 of 1697533\n",
      "580000 of 1697533\n",
      "590000 of 1697533\n",
      "600000 of 1697533\n",
      "610000 of 1697533\n",
      "620000 of 1697533\n",
      "630000 of 1697533\n",
      "640000 of 1697533\n",
      "650000 of 1697533\n",
      "660000 of 1697533\n",
      "670000 of 1697533\n",
      "680000 of 1697533\n",
      "690000 of 1697533\n",
      "700000 of 1697533\n",
      "710000 of 1697533\n",
      "720000 of 1697533\n",
      "730000 of 1697533\n",
      "740000 of 1697533\n",
      "750000 of 1697533\n",
      "760000 of 1697533\n",
      "770000 of 1697533\n",
      "780000 of 1697533\n",
      "790000 of 1697533\n",
      "800000 of 1697533\n",
      "810000 of 1697533\n",
      "820000 of 1697533\n",
      "830000 of 1697533\n",
      "840000 of 1697533\n",
      "850000 of 1697533\n",
      "860000 of 1697533\n",
      "870000 of 1697533\n",
      "880000 of 1697533\n",
      "890000 of 1697533\n",
      "900000 of 1697533\n",
      "910000 of 1697533\n",
      "920000 of 1697533\n",
      "930000 of 1697533\n",
      "940000 of 1697533\n",
      "950000 of 1697533\n",
      "960000 of 1697533\n",
      "970000 of 1697533\n",
      "980000 of 1697533\n",
      "990000 of 1697533\n",
      "1000000 of 1697533\n",
      "1010000 of 1697533\n",
      "1020000 of 1697533\n",
      "1030000 of 1697533\n",
      "1040000 of 1697533\n",
      "1050000 of 1697533\n",
      "1060000 of 1697533\n",
      "1070000 of 1697533\n",
      "1080000 of 1697533\n",
      "1090000 of 1697533\n",
      "1100000 of 1697533\n",
      "1110000 of 1697533\n",
      "1120000 of 1697533\n",
      "1130000 of 1697533\n",
      "1140000 of 1697533\n",
      "1150000 of 1697533\n",
      "1160000 of 1697533\n",
      "1170000 of 1697533\n",
      "1180000 of 1697533\n",
      "1190000 of 1697533\n",
      "1200000 of 1697533\n",
      "1210000 of 1697533\n",
      "1220000 of 1697533\n",
      "1230000 of 1697533\n",
      "1240000 of 1697533\n",
      "1250000 of 1697533\n",
      "1260000 of 1697533\n",
      "1270000 of 1697533\n",
      "1280000 of 1697533\n",
      "1290000 of 1697533\n",
      "1300000 of 1697533\n",
      "1310000 of 1697533\n",
      "1320000 of 1697533\n",
      "1330000 of 1697533\n",
      "1340000 of 1697533\n",
      "1350000 of 1697533\n",
      "1360000 of 1697533\n",
      "1370000 of 1697533\n",
      "1380000 of 1697533\n",
      "1390000 of 1697533\n",
      "1400000 of 1697533\n",
      "1410000 of 1697533\n",
      "1420000 of 1697533\n",
      "1430000 of 1697533\n",
      "1440000 of 1697533\n",
      "1450000 of 1697533\n",
      "1460000 of 1697533\n",
      "1470000 of 1697533\n",
      "1480000 of 1697533\n",
      "1490000 of 1697533\n",
      "1500000 of 1697533\n",
      "1510000 of 1697533\n",
      "1520000 of 1697533\n",
      "1530000 of 1697533\n",
      "1540000 of 1697533\n",
      "1550000 of 1697533\n",
      "1560000 of 1697533\n",
      "1570000 of 1697533\n",
      "1580000 of 1697533\n",
      "1590000 of 1697533\n",
      "1600000 of 1697533\n",
      "1610000 of 1697533\n",
      "1620000 of 1697533\n",
      "1630000 of 1697533\n",
      "1640000 of 1697533\n",
      "1650000 of 1697533\n",
      "1660000 of 1697533\n",
      "1670000 of 1697533\n",
      "1680000 of 1697533\n",
      "1690000 of 1697533\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "with open('labels.txt', 'w') as f:  \n",
    "    ## we need to make a dataset for fasttext\n",
    "    for idx, row in df.iterrows():\n",
    "        ## make sure there are no pesky new line characters\n",
    "        review = row['reviewText'].replace(\"\\n\", \" \")\n",
    "        #rating = \"__label__\" + str(row['overall'])[0]\n",
    "        rating = str(row['overall'])[0]\n",
    "        f.write(rating)\n",
    "        #f.write(\" \")\n",
    "        #f.write(review)\n",
    "        f.write(\"\\n\")\n",
    "        counter += 1\n",
    "        if (counter % 10000 == 0):\n",
    "            print(counter, \"of\", nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### lets hope that the data is not in any sort of order -- we want a random sample for a train / test split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 of 1697533\n",
      "2000 of 1697533\n",
      "3000 of 1697533\n",
      "4000 of 1697533\n",
      "5000 of 1697533\n",
      "6000 of 1697533\n",
      "7000 of 1697533\n",
      "8000 of 1697533\n",
      "9000 of 1697533\n",
      "10000 of 1697533\n",
      "11000 of 1697533\n",
      "12000 of 1697533\n",
      "13000 of 1697533\n",
      "14000 of 1697533\n",
      "15000 of 1697533\n",
      "16000 of 1697533\n",
      "17000 of 1697533\n",
      "18000 of 1697533\n",
      "19000 of 1697533\n",
      "20000 of 1697533\n",
      "21000 of 1697533\n",
      "22000 of 1697533\n",
      "23000 of 1697533\n",
      "24000 of 1697533\n",
      "25000 of 1697533\n",
      "26000 of 1697533\n",
      "27000 of 1697533\n",
      "28000 of 1697533\n",
      "29000 of 1697533\n",
      "30000 of 1697533\n",
      "31000 of 1697533\n",
      "32000 of 1697533\n",
      "33000 of 1697533\n",
      "34000 of 1697533\n",
      "35000 of 1697533\n",
      "36000 of 1697533\n",
      "37000 of 1697533\n",
      "38000 of 1697533\n",
      "39000 of 1697533\n",
      "40000 of 1697533\n",
      "41000 of 1697533\n",
      "42000 of 1697533\n",
      "43000 of 1697533\n",
      "44000 of 1697533\n",
      "45000 of 1697533\n",
      "46000 of 1697533\n",
      "47000 of 1697533\n",
      "48000 of 1697533\n",
      "49000 of 1697533\n",
      "50000 of 1697533\n",
      "51000 of 1697533\n",
      "52000 of 1697533\n",
      "53000 of 1697533\n",
      "54000 of 1697533\n",
      "55000 of 1697533\n",
      "56000 of 1697533\n",
      "57000 of 1697533\n",
      "58000 of 1697533\n",
      "59000 of 1697533\n",
      "60000 of 1697533\n",
      "61000 of 1697533\n",
      "62000 of 1697533\n",
      "63000 of 1697533\n",
      "64000 of 1697533\n",
      "65000 of 1697533\n",
      "66000 of 1697533\n",
      "67000 of 1697533\n",
      "68000 of 1697533\n",
      "69000 of 1697533\n",
      "70000 of 1697533\n",
      "71000 of 1697533\n",
      "72000 of 1697533\n",
      "73000 of 1697533\n",
      "74000 of 1697533\n",
      "75000 of 1697533\n",
      "76000 of 1697533\n",
      "77000 of 1697533\n",
      "78000 of 1697533\n",
      "79000 of 1697533\n",
      "80000 of 1697533\n",
      "81000 of 1697533\n",
      "82000 of 1697533\n",
      "83000 of 1697533\n",
      "84000 of 1697533\n",
      "85000 of 1697533\n",
      "86000 of 1697533\n",
      "87000 of 1697533\n",
      "88000 of 1697533\n",
      "89000 of 1697533\n",
      "90000 of 1697533\n",
      "91000 of 1697533\n",
      "92000 of 1697533\n",
      "93000 of 1697533\n",
      "94000 of 1697533\n",
      "95000 of 1697533\n",
      "96000 of 1697533\n",
      "97000 of 1697533\n",
      "98000 of 1697533\n",
      "99000 of 1697533\n",
      "100000 of 1697533\n",
      "101000 of 1697533\n",
      "102000 of 1697533\n",
      "103000 of 1697533\n",
      "104000 of 1697533\n",
      "105000 of 1697533\n",
      "106000 of 1697533\n",
      "107000 of 1697533\n",
      "108000 of 1697533\n",
      "109000 of 1697533\n",
      "110000 of 1697533\n",
      "111000 of 1697533\n",
      "112000 of 1697533\n",
      "113000 of 1697533\n",
      "114000 of 1697533\n",
      "115000 of 1697533\n",
      "116000 of 1697533\n",
      "117000 of 1697533\n",
      "118000 of 1697533\n",
      "119000 of 1697533\n",
      "120000 of 1697533\n",
      "121000 of 1697533\n",
      "122000 of 1697533\n",
      "123000 of 1697533\n",
      "124000 of 1697533\n",
      "125000 of 1697533\n",
      "126000 of 1697533\n",
      "127000 of 1697533\n",
      "128000 of 1697533\n",
      "129000 of 1697533\n",
      "130000 of 1697533\n",
      "131000 of 1697533\n",
      "132000 of 1697533\n",
      "133000 of 1697533\n",
      "134000 of 1697533\n",
      "135000 of 1697533\n",
      "136000 of 1697533\n",
      "137000 of 1697533\n",
      "138000 of 1697533\n",
      "139000 of 1697533\n",
      "140000 of 1697533\n",
      "141000 of 1697533\n",
      "142000 of 1697533\n",
      "143000 of 1697533\n",
      "144000 of 1697533\n",
      "145000 of 1697533\n",
      "146000 of 1697533\n",
      "147000 of 1697533\n",
      "148000 of 1697533\n",
      "149000 of 1697533\n",
      "150000 of 1697533\n",
      "151000 of 1697533\n",
      "152000 of 1697533\n",
      "153000 of 1697533\n",
      "154000 of 1697533\n",
      "155000 of 1697533\n",
      "156000 of 1697533\n",
      "157000 of 1697533\n",
      "158000 of 1697533\n",
      "159000 of 1697533\n",
      "160000 of 1697533\n",
      "161000 of 1697533\n",
      "162000 of 1697533\n",
      "163000 of 1697533\n",
      "164000 of 1697533\n",
      "165000 of 1697533\n",
      "166000 of 1697533\n",
      "167000 of 1697533\n",
      "168000 of 1697533\n",
      "169000 of 1697533\n",
      "170000 of 1697533\n",
      "171000 of 1697533\n",
      "172000 of 1697533\n",
      "173000 of 1697533\n",
      "174000 of 1697533\n",
      "175000 of 1697533\n",
      "176000 of 1697533\n",
      "177000 of 1697533\n",
      "178000 of 1697533\n",
      "179000 of 1697533\n",
      "180000 of 1697533\n",
      "181000 of 1697533\n",
      "182000 of 1697533\n",
      "183000 of 1697533\n",
      "184000 of 1697533\n",
      "185000 of 1697533\n",
      "186000 of 1697533\n",
      "187000 of 1697533\n",
      "188000 of 1697533\n",
      "189000 of 1697533\n",
      "190000 of 1697533\n",
      "191000 of 1697533\n",
      "192000 of 1697533\n",
      "193000 of 1697533\n",
      "194000 of 1697533\n",
      "195000 of 1697533\n",
      "196000 of 1697533\n",
      "197000 of 1697533\n",
      "198000 of 1697533\n",
      "199000 of 1697533\n",
      "200000 of 1697533\n",
      "201000 of 1697533\n",
      "202000 of 1697533\n",
      "203000 of 1697533\n",
      "204000 of 1697533\n",
      "205000 of 1697533\n",
      "206000 of 1697533\n",
      "207000 of 1697533\n",
      "208000 of 1697533\n",
      "209000 of 1697533\n",
      "210000 of 1697533\n",
      "211000 of 1697533\n",
      "212000 of 1697533\n",
      "213000 of 1697533\n",
      "214000 of 1697533\n",
      "215000 of 1697533\n",
      "216000 of 1697533\n",
      "217000 of 1697533\n",
      "218000 of 1697533\n",
      "219000 of 1697533\n",
      "220000 of 1697533\n",
      "221000 of 1697533\n",
      "222000 of 1697533\n",
      "223000 of 1697533\n",
      "224000 of 1697533\n",
      "225000 of 1697533\n",
      "226000 of 1697533\n",
      "227000 of 1697533\n",
      "228000 of 1697533\n",
      "229000 of 1697533\n",
      "230000 of 1697533\n",
      "231000 of 1697533\n",
      "232000 of 1697533\n",
      "233000 of 1697533\n",
      "234000 of 1697533\n",
      "235000 of 1697533\n",
      "236000 of 1697533\n",
      "237000 of 1697533\n",
      "238000 of 1697533\n",
      "239000 of 1697533\n",
      "240000 of 1697533\n",
      "241000 of 1697533\n",
      "242000 of 1697533\n",
      "243000 of 1697533\n",
      "244000 of 1697533\n",
      "245000 of 1697533\n",
      "246000 of 1697533\n",
      "247000 of 1697533\n",
      "248000 of 1697533\n",
      "249000 of 1697533\n",
      "250000 of 1697533\n",
      "251000 of 1697533\n",
      "252000 of 1697533\n",
      "253000 of 1697533\n",
      "254000 of 1697533\n",
      "255000 of 1697533\n",
      "256000 of 1697533\n",
      "257000 of 1697533\n",
      "258000 of 1697533\n",
      "259000 of 1697533\n",
      "260000 of 1697533\n",
      "261000 of 1697533\n",
      "262000 of 1697533\n",
      "263000 of 1697533\n",
      "264000 of 1697533\n",
      "265000 of 1697533\n",
      "266000 of 1697533\n",
      "267000 of 1697533\n",
      "268000 of 1697533\n",
      "269000 of 1697533\n",
      "270000 of 1697533\n",
      "271000 of 1697533\n",
      "272000 of 1697533\n",
      "273000 of 1697533\n",
      "274000 of 1697533\n",
      "275000 of 1697533\n",
      "276000 of 1697533\n",
      "277000 of 1697533\n",
      "278000 of 1697533\n",
      "279000 of 1697533\n",
      "280000 of 1697533\n",
      "281000 of 1697533\n",
      "282000 of 1697533\n",
      "283000 of 1697533\n",
      "284000 of 1697533\n",
      "285000 of 1697533\n",
      "286000 of 1697533\n",
      "287000 of 1697533\n",
      "288000 of 1697533\n",
      "289000 of 1697533\n",
      "290000 of 1697533\n",
      "291000 of 1697533\n",
      "292000 of 1697533\n",
      "293000 of 1697533\n",
      "294000 of 1697533\n",
      "295000 of 1697533\n",
      "296000 of 1697533\n",
      "297000 of 1697533\n",
      "298000 of 1697533\n",
      "299000 of 1697533\n",
      "300000 of 1697533\n",
      "301000 of 1697533\n",
      "302000 of 1697533\n",
      "303000 of 1697533\n",
      "304000 of 1697533\n",
      "305000 of 1697533\n",
      "306000 of 1697533\n",
      "307000 of 1697533\n",
      "308000 of 1697533\n",
      "309000 of 1697533\n",
      "310000 of 1697533\n",
      "311000 of 1697533\n",
      "312000 of 1697533\n",
      "313000 of 1697533\n",
      "314000 of 1697533\n",
      "315000 of 1697533\n",
      "316000 of 1697533\n",
      "317000 of 1697533\n",
      "318000 of 1697533\n",
      "319000 of 1697533\n",
      "320000 of 1697533\n",
      "321000 of 1697533\n",
      "322000 of 1697533\n",
      "323000 of 1697533\n",
      "324000 of 1697533\n",
      "325000 of 1697533\n",
      "326000 of 1697533\n",
      "327000 of 1697533\n",
      "328000 of 1697533\n",
      "329000 of 1697533\n",
      "330000 of 1697533\n",
      "331000 of 1697533\n",
      "332000 of 1697533\n",
      "333000 of 1697533\n",
      "334000 of 1697533\n",
      "335000 of 1697533\n",
      "336000 of 1697533\n",
      "337000 of 1697533\n",
      "338000 of 1697533\n",
      "339000 of 1697533\n",
      "340000 of 1697533\n",
      "341000 of 1697533\n",
      "342000 of 1697533\n",
      "343000 of 1697533\n",
      "344000 of 1697533\n",
      "345000 of 1697533\n",
      "346000 of 1697533\n",
      "347000 of 1697533\n",
      "348000 of 1697533\n",
      "349000 of 1697533\n",
      "350000 of 1697533\n",
      "351000 of 1697533\n",
      "352000 of 1697533\n",
      "353000 of 1697533\n",
      "354000 of 1697533\n",
      "355000 of 1697533\n",
      "356000 of 1697533\n",
      "357000 of 1697533\n",
      "358000 of 1697533\n",
      "359000 of 1697533\n",
      "360000 of 1697533\n",
      "361000 of 1697533\n",
      "362000 of 1697533\n",
      "363000 of 1697533\n",
      "364000 of 1697533\n",
      "365000 of 1697533\n",
      "366000 of 1697533\n",
      "367000 of 1697533\n",
      "368000 of 1697533\n",
      "369000 of 1697533\n",
      "370000 of 1697533\n",
      "371000 of 1697533\n",
      "372000 of 1697533\n",
      "373000 of 1697533\n",
      "374000 of 1697533\n",
      "375000 of 1697533\n",
      "376000 of 1697533\n",
      "377000 of 1697533\n",
      "378000 of 1697533\n",
      "379000 of 1697533\n",
      "380000 of 1697533\n",
      "381000 of 1697533\n",
      "382000 of 1697533\n",
      "383000 of 1697533\n",
      "384000 of 1697533\n",
      "385000 of 1697533\n",
      "386000 of 1697533\n",
      "387000 of 1697533\n",
      "388000 of 1697533\n",
      "389000 of 1697533\n",
      "390000 of 1697533\n",
      "391000 of 1697533\n",
      "392000 of 1697533\n",
      "393000 of 1697533\n",
      "394000 of 1697533\n",
      "395000 of 1697533\n",
      "396000 of 1697533\n",
      "397000 of 1697533\n",
      "398000 of 1697533\n",
      "399000 of 1697533\n",
      "400000 of 1697533\n",
      "401000 of 1697533\n",
      "402000 of 1697533\n",
      "403000 of 1697533\n",
      "404000 of 1697533\n",
      "405000 of 1697533\n",
      "406000 of 1697533\n",
      "407000 of 1697533\n",
      "408000 of 1697533\n",
      "409000 of 1697533\n",
      "410000 of 1697533\n",
      "411000 of 1697533\n",
      "412000 of 1697533\n",
      "413000 of 1697533\n",
      "414000 of 1697533\n",
      "415000 of 1697533\n",
      "416000 of 1697533\n",
      "417000 of 1697533\n",
      "418000 of 1697533\n",
      "419000 of 1697533\n",
      "420000 of 1697533\n",
      "421000 of 1697533\n",
      "422000 of 1697533\n",
      "423000 of 1697533\n",
      "424000 of 1697533\n",
      "425000 of 1697533\n",
      "426000 of 1697533\n",
      "427000 of 1697533\n",
      "428000 of 1697533\n",
      "429000 of 1697533\n",
      "430000 of 1697533\n",
      "431000 of 1697533\n",
      "432000 of 1697533\n",
      "433000 of 1697533\n",
      "434000 of 1697533\n",
      "435000 of 1697533\n",
      "436000 of 1697533\n",
      "437000 of 1697533\n",
      "438000 of 1697533\n",
      "439000 of 1697533\n",
      "440000 of 1697533\n",
      "441000 of 1697533\n",
      "442000 of 1697533\n",
      "443000 of 1697533\n",
      "444000 of 1697533\n",
      "445000 of 1697533\n",
      "446000 of 1697533\n",
      "447000 of 1697533\n",
      "448000 of 1697533\n",
      "449000 of 1697533\n",
      "450000 of 1697533\n",
      "451000 of 1697533\n",
      "452000 of 1697533\n",
      "453000 of 1697533\n",
      "454000 of 1697533\n",
      "455000 of 1697533\n",
      "456000 of 1697533\n",
      "457000 of 1697533\n",
      "458000 of 1697533\n",
      "459000 of 1697533\n",
      "460000 of 1697533\n",
      "461000 of 1697533\n",
      "462000 of 1697533\n",
      "463000 of 1697533\n",
      "464000 of 1697533\n",
      "465000 of 1697533\n",
      "466000 of 1697533\n",
      "467000 of 1697533\n",
      "468000 of 1697533\n",
      "469000 of 1697533\n",
      "470000 of 1697533\n",
      "471000 of 1697533\n",
      "472000 of 1697533\n",
      "473000 of 1697533\n",
      "474000 of 1697533\n",
      "475000 of 1697533\n",
      "476000 of 1697533\n",
      "477000 of 1697533\n",
      "478000 of 1697533\n",
      "479000 of 1697533\n",
      "480000 of 1697533\n",
      "481000 of 1697533\n",
      "482000 of 1697533\n",
      "483000 of 1697533\n",
      "484000 of 1697533\n",
      "485000 of 1697533\n",
      "486000 of 1697533\n",
      "487000 of 1697533\n",
      "488000 of 1697533\n",
      "489000 of 1697533\n",
      "490000 of 1697533\n",
      "491000 of 1697533\n",
      "492000 of 1697533\n",
      "493000 of 1697533\n",
      "494000 of 1697533\n",
      "495000 of 1697533\n",
      "496000 of 1697533\n",
      "497000 of 1697533\n",
      "498000 of 1697533\n",
      "499000 of 1697533\n",
      "500000 of 1697533\n",
      "501000 of 1697533\n",
      "502000 of 1697533\n",
      "503000 of 1697533\n",
      "504000 of 1697533\n",
      "505000 of 1697533\n",
      "506000 of 1697533\n",
      "507000 of 1697533\n",
      "508000 of 1697533\n",
      "509000 of 1697533\n",
      "510000 of 1697533\n",
      "511000 of 1697533\n",
      "512000 of 1697533\n",
      "513000 of 1697533\n",
      "514000 of 1697533\n",
      "515000 of 1697533\n",
      "516000 of 1697533\n",
      "517000 of 1697533\n",
      "518000 of 1697533\n",
      "519000 of 1697533\n",
      "520000 of 1697533\n",
      "521000 of 1697533\n",
      "522000 of 1697533\n",
      "523000 of 1697533\n",
      "524000 of 1697533\n",
      "525000 of 1697533\n",
      "526000 of 1697533\n",
      "527000 of 1697533\n",
      "528000 of 1697533\n",
      "529000 of 1697533\n",
      "530000 of 1697533\n",
      "531000 of 1697533\n",
      "532000 of 1697533\n",
      "533000 of 1697533\n",
      "534000 of 1697533\n",
      "535000 of 1697533\n",
      "536000 of 1697533\n",
      "537000 of 1697533\n",
      "538000 of 1697533\n",
      "539000 of 1697533\n",
      "540000 of 1697533\n",
      "541000 of 1697533\n",
      "542000 of 1697533\n",
      "543000 of 1697533\n",
      "544000 of 1697533\n",
      "545000 of 1697533\n",
      "546000 of 1697533\n",
      "547000 of 1697533\n",
      "548000 of 1697533\n",
      "549000 of 1697533\n",
      "550000 of 1697533\n",
      "551000 of 1697533\n",
      "552000 of 1697533\n",
      "553000 of 1697533\n",
      "554000 of 1697533\n",
      "555000 of 1697533\n",
      "556000 of 1697533\n",
      "557000 of 1697533\n",
      "558000 of 1697533\n",
      "559000 of 1697533\n",
      "560000 of 1697533\n",
      "561000 of 1697533\n",
      "562000 of 1697533\n",
      "563000 of 1697533\n",
      "564000 of 1697533\n",
      "565000 of 1697533\n",
      "566000 of 1697533\n",
      "567000 of 1697533\n",
      "568000 of 1697533\n",
      "569000 of 1697533\n",
      "570000 of 1697533\n",
      "571000 of 1697533\n",
      "572000 of 1697533\n",
      "573000 of 1697533\n",
      "574000 of 1697533\n",
      "575000 of 1697533\n",
      "576000 of 1697533\n",
      "577000 of 1697533\n",
      "578000 of 1697533\n",
      "579000 of 1697533\n",
      "580000 of 1697533\n",
      "581000 of 1697533\n",
      "582000 of 1697533\n",
      "583000 of 1697533\n",
      "584000 of 1697533\n",
      "585000 of 1697533\n",
      "586000 of 1697533\n",
      "587000 of 1697533\n",
      "588000 of 1697533\n",
      "589000 of 1697533\n",
      "590000 of 1697533\n",
      "591000 of 1697533\n",
      "592000 of 1697533\n",
      "593000 of 1697533\n",
      "594000 of 1697533\n",
      "595000 of 1697533\n",
      "596000 of 1697533\n",
      "597000 of 1697533\n",
      "598000 of 1697533\n",
      "599000 of 1697533\n",
      "600000 of 1697533\n",
      "601000 of 1697533\n",
      "602000 of 1697533\n",
      "603000 of 1697533\n",
      "604000 of 1697533\n",
      "605000 of 1697533\n",
      "606000 of 1697533\n",
      "607000 of 1697533\n",
      "608000 of 1697533\n",
      "609000 of 1697533\n",
      "610000 of 1697533\n",
      "611000 of 1697533\n",
      "612000 of 1697533\n",
      "613000 of 1697533\n",
      "614000 of 1697533\n",
      "615000 of 1697533\n",
      "616000 of 1697533\n",
      "617000 of 1697533\n",
      "618000 of 1697533\n",
      "619000 of 1697533\n",
      "620000 of 1697533\n",
      "621000 of 1697533\n",
      "622000 of 1697533\n",
      "623000 of 1697533\n",
      "624000 of 1697533\n",
      "625000 of 1697533\n",
      "626000 of 1697533\n",
      "627000 of 1697533\n",
      "628000 of 1697533\n",
      "629000 of 1697533\n",
      "630000 of 1697533\n",
      "631000 of 1697533\n",
      "632000 of 1697533\n",
      "633000 of 1697533\n",
      "634000 of 1697533\n",
      "635000 of 1697533\n",
      "636000 of 1697533\n",
      "637000 of 1697533\n",
      "638000 of 1697533\n",
      "639000 of 1697533\n",
      "640000 of 1697533\n",
      "641000 of 1697533\n",
      "642000 of 1697533\n",
      "643000 of 1697533\n",
      "644000 of 1697533\n",
      "645000 of 1697533\n",
      "646000 of 1697533\n",
      "647000 of 1697533\n",
      "648000 of 1697533\n",
      "649000 of 1697533\n",
      "650000 of 1697533\n",
      "651000 of 1697533\n",
      "652000 of 1697533\n",
      "653000 of 1697533\n",
      "654000 of 1697533\n",
      "655000 of 1697533\n",
      "656000 of 1697533\n",
      "657000 of 1697533\n",
      "658000 of 1697533\n",
      "659000 of 1697533\n",
      "660000 of 1697533\n",
      "661000 of 1697533\n",
      "662000 of 1697533\n",
      "663000 of 1697533\n",
      "664000 of 1697533\n",
      "665000 of 1697533\n",
      "666000 of 1697533\n",
      "667000 of 1697533\n",
      "668000 of 1697533\n",
      "669000 of 1697533\n",
      "670000 of 1697533\n",
      "671000 of 1697533\n",
      "672000 of 1697533\n",
      "673000 of 1697533\n",
      "674000 of 1697533\n",
      "675000 of 1697533\n",
      "676000 of 1697533\n",
      "677000 of 1697533\n",
      "678000 of 1697533\n",
      "679000 of 1697533\n",
      "680000 of 1697533\n",
      "681000 of 1697533\n",
      "682000 of 1697533\n",
      "683000 of 1697533\n",
      "684000 of 1697533\n",
      "685000 of 1697533\n",
      "686000 of 1697533\n",
      "687000 of 1697533\n",
      "688000 of 1697533\n",
      "689000 of 1697533\n",
      "690000 of 1697533\n",
      "691000 of 1697533\n",
      "692000 of 1697533\n",
      "693000 of 1697533\n",
      "694000 of 1697533\n",
      "695000 of 1697533\n",
      "696000 of 1697533\n",
      "697000 of 1697533\n",
      "698000 of 1697533\n",
      "699000 of 1697533\n",
      "700000 of 1697533\n",
      "701000 of 1697533\n",
      "702000 of 1697533\n",
      "703000 of 1697533\n",
      "704000 of 1697533\n",
      "705000 of 1697533\n",
      "706000 of 1697533\n",
      "707000 of 1697533\n",
      "708000 of 1697533\n",
      "709000 of 1697533\n",
      "710000 of 1697533\n",
      "711000 of 1697533\n",
      "712000 of 1697533\n",
      "713000 of 1697533\n",
      "714000 of 1697533\n",
      "715000 of 1697533\n",
      "716000 of 1697533\n",
      "717000 of 1697533\n",
      "718000 of 1697533\n",
      "719000 of 1697533\n",
      "720000 of 1697533\n",
      "721000 of 1697533\n",
      "722000 of 1697533\n",
      "723000 of 1697533\n",
      "724000 of 1697533\n",
      "725000 of 1697533\n",
      "726000 of 1697533\n",
      "727000 of 1697533\n",
      "728000 of 1697533\n",
      "729000 of 1697533\n",
      "730000 of 1697533\n",
      "731000 of 1697533\n",
      "732000 of 1697533\n",
      "733000 of 1697533\n",
      "734000 of 1697533\n",
      "735000 of 1697533\n",
      "736000 of 1697533\n",
      "737000 of 1697533\n",
      "738000 of 1697533\n",
      "739000 of 1697533\n",
      "740000 of 1697533\n",
      "741000 of 1697533\n",
      "742000 of 1697533\n",
      "743000 of 1697533\n",
      "744000 of 1697533\n",
      "745000 of 1697533\n",
      "746000 of 1697533\n",
      "747000 of 1697533\n",
      "748000 of 1697533\n",
      "749000 of 1697533\n",
      "750000 of 1697533\n",
      "751000 of 1697533\n",
      "752000 of 1697533\n",
      "753000 of 1697533\n",
      "754000 of 1697533\n",
      "755000 of 1697533\n",
      "756000 of 1697533\n",
      "757000 of 1697533\n",
      "758000 of 1697533\n",
      "759000 of 1697533\n",
      "760000 of 1697533\n",
      "761000 of 1697533\n",
      "762000 of 1697533\n",
      "763000 of 1697533\n",
      "764000 of 1697533\n",
      "765000 of 1697533\n",
      "766000 of 1697533\n",
      "767000 of 1697533\n",
      "768000 of 1697533\n",
      "769000 of 1697533\n",
      "770000 of 1697533\n",
      "771000 of 1697533\n",
      "772000 of 1697533\n",
      "773000 of 1697533\n",
      "774000 of 1697533\n",
      "775000 of 1697533\n",
      "776000 of 1697533\n",
      "777000 of 1697533\n",
      "778000 of 1697533\n",
      "779000 of 1697533\n",
      "780000 of 1697533\n",
      "781000 of 1697533\n",
      "782000 of 1697533\n",
      "783000 of 1697533\n",
      "784000 of 1697533\n",
      "785000 of 1697533\n",
      "786000 of 1697533\n",
      "787000 of 1697533\n",
      "788000 of 1697533\n",
      "789000 of 1697533\n",
      "790000 of 1697533\n",
      "791000 of 1697533\n",
      "792000 of 1697533\n",
      "793000 of 1697533\n",
      "794000 of 1697533\n",
      "795000 of 1697533\n",
      "796000 of 1697533\n",
      "797000 of 1697533\n",
      "798000 of 1697533\n",
      "799000 of 1697533\n",
      "800000 of 1697533\n",
      "801000 of 1697533\n",
      "802000 of 1697533\n",
      "803000 of 1697533\n",
      "804000 of 1697533\n",
      "805000 of 1697533\n",
      "806000 of 1697533\n",
      "807000 of 1697533\n",
      "808000 of 1697533\n",
      "809000 of 1697533\n",
      "810000 of 1697533\n",
      "811000 of 1697533\n",
      "812000 of 1697533\n",
      "813000 of 1697533\n",
      "814000 of 1697533\n",
      "815000 of 1697533\n",
      "816000 of 1697533\n",
      "817000 of 1697533\n",
      "818000 of 1697533\n",
      "819000 of 1697533\n",
      "820000 of 1697533\n",
      "821000 of 1697533\n",
      "822000 of 1697533\n",
      "823000 of 1697533\n",
      "824000 of 1697533\n",
      "825000 of 1697533\n",
      "826000 of 1697533\n",
      "827000 of 1697533\n",
      "828000 of 1697533\n",
      "829000 of 1697533\n",
      "830000 of 1697533\n",
      "831000 of 1697533\n",
      "832000 of 1697533\n",
      "833000 of 1697533\n",
      "834000 of 1697533\n",
      "835000 of 1697533\n",
      "836000 of 1697533\n",
      "837000 of 1697533\n",
      "838000 of 1697533\n",
      "839000 of 1697533\n",
      "840000 of 1697533\n",
      "841000 of 1697533\n",
      "842000 of 1697533\n",
      "843000 of 1697533\n",
      "844000 of 1697533\n",
      "845000 of 1697533\n",
      "846000 of 1697533\n",
      "847000 of 1697533\n",
      "848000 of 1697533\n",
      "849000 of 1697533\n",
      "850000 of 1697533\n",
      "851000 of 1697533\n",
      "852000 of 1697533\n",
      "853000 of 1697533\n",
      "854000 of 1697533\n",
      "855000 of 1697533\n",
      "856000 of 1697533\n",
      "857000 of 1697533\n",
      "858000 of 1697533\n",
      "859000 of 1697533\n",
      "860000 of 1697533\n",
      "861000 of 1697533\n",
      "862000 of 1697533\n",
      "863000 of 1697533\n",
      "864000 of 1697533\n",
      "865000 of 1697533\n",
      "866000 of 1697533\n",
      "867000 of 1697533\n",
      "868000 of 1697533\n",
      "869000 of 1697533\n",
      "870000 of 1697533\n",
      "871000 of 1697533\n",
      "872000 of 1697533\n",
      "873000 of 1697533\n",
      "874000 of 1697533\n",
      "875000 of 1697533\n",
      "876000 of 1697533\n",
      "877000 of 1697533\n",
      "878000 of 1697533\n",
      "879000 of 1697533\n",
      "880000 of 1697533\n",
      "881000 of 1697533\n",
      "882000 of 1697533\n",
      "883000 of 1697533\n",
      "884000 of 1697533\n",
      "885000 of 1697533\n",
      "886000 of 1697533\n",
      "887000 of 1697533\n",
      "888000 of 1697533\n",
      "889000 of 1697533\n",
      "890000 of 1697533\n",
      "891000 of 1697533\n",
      "892000 of 1697533\n",
      "893000 of 1697533\n",
      "894000 of 1697533\n",
      "895000 of 1697533\n",
      "896000 of 1697533\n",
      "897000 of 1697533\n",
      "898000 of 1697533\n",
      "899000 of 1697533\n",
      "900000 of 1697533\n",
      "901000 of 1697533\n",
      "902000 of 1697533\n",
      "903000 of 1697533\n",
      "904000 of 1697533\n",
      "905000 of 1697533\n",
      "906000 of 1697533\n",
      "907000 of 1697533\n",
      "908000 of 1697533\n",
      "909000 of 1697533\n",
      "910000 of 1697533\n",
      "911000 of 1697533\n",
      "912000 of 1697533\n",
      "913000 of 1697533\n",
      "914000 of 1697533\n",
      "915000 of 1697533\n",
      "916000 of 1697533\n",
      "917000 of 1697533\n",
      "918000 of 1697533\n",
      "919000 of 1697533\n",
      "920000 of 1697533\n",
      "921000 of 1697533\n",
      "922000 of 1697533\n",
      "923000 of 1697533\n",
      "924000 of 1697533\n",
      "925000 of 1697533\n",
      "926000 of 1697533\n",
      "927000 of 1697533\n",
      "928000 of 1697533\n",
      "929000 of 1697533\n",
      "930000 of 1697533\n",
      "931000 of 1697533\n",
      "932000 of 1697533\n",
      "933000 of 1697533\n",
      "934000 of 1697533\n",
      "935000 of 1697533\n",
      "936000 of 1697533\n",
      "937000 of 1697533\n",
      "938000 of 1697533\n",
      "939000 of 1697533\n",
      "940000 of 1697533\n",
      "941000 of 1697533\n",
      "942000 of 1697533\n",
      "943000 of 1697533\n",
      "944000 of 1697533\n",
      "945000 of 1697533\n",
      "946000 of 1697533\n",
      "947000 of 1697533\n",
      "948000 of 1697533\n",
      "949000 of 1697533\n",
      "950000 of 1697533\n",
      "951000 of 1697533\n",
      "952000 of 1697533\n",
      "953000 of 1697533\n",
      "954000 of 1697533\n",
      "955000 of 1697533\n",
      "956000 of 1697533\n",
      "957000 of 1697533\n",
      "958000 of 1697533\n",
      "959000 of 1697533\n",
      "960000 of 1697533\n",
      "961000 of 1697533\n",
      "962000 of 1697533\n",
      "963000 of 1697533\n",
      "964000 of 1697533\n",
      "965000 of 1697533\n",
      "966000 of 1697533\n",
      "967000 of 1697533\n",
      "968000 of 1697533\n",
      "969000 of 1697533\n",
      "970000 of 1697533\n",
      "971000 of 1697533\n",
      "972000 of 1697533\n",
      "973000 of 1697533\n",
      "974000 of 1697533\n",
      "975000 of 1697533\n",
      "976000 of 1697533\n",
      "977000 of 1697533\n",
      "978000 of 1697533\n",
      "979000 of 1697533\n",
      "980000 of 1697533\n",
      "981000 of 1697533\n",
      "982000 of 1697533\n",
      "983000 of 1697533\n",
      "984000 of 1697533\n",
      "985000 of 1697533\n",
      "986000 of 1697533\n",
      "987000 of 1697533\n",
      "988000 of 1697533\n",
      "989000 of 1697533\n",
      "990000 of 1697533\n",
      "991000 of 1697533\n",
      "992000 of 1697533\n",
      "993000 of 1697533\n",
      "994000 of 1697533\n",
      "995000 of 1697533\n",
      "996000 of 1697533\n",
      "997000 of 1697533\n",
      "998000 of 1697533\n",
      "999000 of 1697533\n",
      "1000000 of 1697533\n",
      "1001000 of 1697533\n",
      "1002000 of 1697533\n",
      "1003000 of 1697533\n",
      "1004000 of 1697533\n",
      "1005000 of 1697533\n",
      "1006000 of 1697533\n",
      "1007000 of 1697533\n",
      "1008000 of 1697533\n",
      "1009000 of 1697533\n",
      "1010000 of 1697533\n",
      "1011000 of 1697533\n",
      "1012000 of 1697533\n",
      "1013000 of 1697533\n",
      "1014000 of 1697533\n",
      "1015000 of 1697533\n",
      "1016000 of 1697533\n",
      "1017000 of 1697533\n",
      "1018000 of 1697533\n",
      "1019000 of 1697533\n",
      "1020000 of 1697533\n",
      "1021000 of 1697533\n",
      "1022000 of 1697533\n",
      "1023000 of 1697533\n",
      "1024000 of 1697533\n",
      "1025000 of 1697533\n",
      "1026000 of 1697533\n",
      "1027000 of 1697533\n",
      "1028000 of 1697533\n",
      "1029000 of 1697533\n",
      "1030000 of 1697533\n",
      "1031000 of 1697533\n",
      "1032000 of 1697533\n",
      "1033000 of 1697533\n",
      "1034000 of 1697533\n",
      "1035000 of 1697533\n",
      "1036000 of 1697533\n",
      "1037000 of 1697533\n",
      "1038000 of 1697533\n",
      "1039000 of 1697533\n",
      "1040000 of 1697533\n",
      "1041000 of 1697533\n",
      "1042000 of 1697533\n",
      "1043000 of 1697533\n",
      "1044000 of 1697533\n",
      "1045000 of 1697533\n",
      "1046000 of 1697533\n",
      "1047000 of 1697533\n",
      "1048000 of 1697533\n",
      "1049000 of 1697533\n",
      "1050000 of 1697533\n",
      "1051000 of 1697533\n",
      "1052000 of 1697533\n",
      "1053000 of 1697533\n",
      "1054000 of 1697533\n",
      "1055000 of 1697533\n",
      "1056000 of 1697533\n",
      "1057000 of 1697533\n",
      "1058000 of 1697533\n",
      "1059000 of 1697533\n",
      "1060000 of 1697533\n",
      "1061000 of 1697533\n",
      "1062000 of 1697533\n",
      "1063000 of 1697533\n",
      "1064000 of 1697533\n",
      "1065000 of 1697533\n",
      "1066000 of 1697533\n",
      "1067000 of 1697533\n",
      "1068000 of 1697533\n",
      "1069000 of 1697533\n",
      "1070000 of 1697533\n",
      "1071000 of 1697533\n",
      "1072000 of 1697533\n",
      "1073000 of 1697533\n",
      "1074000 of 1697533\n",
      "1075000 of 1697533\n",
      "1076000 of 1697533\n",
      "1077000 of 1697533\n",
      "1078000 of 1697533\n",
      "1079000 of 1697533\n",
      "1080000 of 1697533\n",
      "1081000 of 1697533\n",
      "1082000 of 1697533\n",
      "1083000 of 1697533\n",
      "1084000 of 1697533\n",
      "1085000 of 1697533\n",
      "1086000 of 1697533\n",
      "1087000 of 1697533\n",
      "1088000 of 1697533\n",
      "1089000 of 1697533\n",
      "1090000 of 1697533\n",
      "1091000 of 1697533\n",
      "1092000 of 1697533\n",
      "1093000 of 1697533\n",
      "1094000 of 1697533\n",
      "1095000 of 1697533\n",
      "1096000 of 1697533\n",
      "1097000 of 1697533\n",
      "1098000 of 1697533\n",
      "1099000 of 1697533\n",
      "1100000 of 1697533\n",
      "1101000 of 1697533\n",
      "1102000 of 1697533\n",
      "1103000 of 1697533\n",
      "1104000 of 1697533\n",
      "1105000 of 1697533\n",
      "1106000 of 1697533\n",
      "1107000 of 1697533\n",
      "1108000 of 1697533\n",
      "1109000 of 1697533\n",
      "1110000 of 1697533\n",
      "1111000 of 1697533\n",
      "1112000 of 1697533\n",
      "1113000 of 1697533\n",
      "1114000 of 1697533\n",
      "1115000 of 1697533\n",
      "1116000 of 1697533\n",
      "1117000 of 1697533\n",
      "1118000 of 1697533\n",
      "1119000 of 1697533\n",
      "1120000 of 1697533\n",
      "1121000 of 1697533\n",
      "1122000 of 1697533\n",
      "1123000 of 1697533\n",
      "1124000 of 1697533\n",
      "1125000 of 1697533\n",
      "1126000 of 1697533\n",
      "1127000 of 1697533\n",
      "1128000 of 1697533\n",
      "1129000 of 1697533\n",
      "1130000 of 1697533\n",
      "1131000 of 1697533\n",
      "1132000 of 1697533\n",
      "1133000 of 1697533\n",
      "1134000 of 1697533\n",
      "1135000 of 1697533\n",
      "1136000 of 1697533\n",
      "1137000 of 1697533\n",
      "1138000 of 1697533\n",
      "1139000 of 1697533\n",
      "1140000 of 1697533\n",
      "1141000 of 1697533\n",
      "1142000 of 1697533\n",
      "1143000 of 1697533\n",
      "1144000 of 1697533\n",
      "1145000 of 1697533\n",
      "1146000 of 1697533\n",
      "1147000 of 1697533\n",
      "1148000 of 1697533\n",
      "1149000 of 1697533\n",
      "1150000 of 1697533\n",
      "1151000 of 1697533\n",
      "1152000 of 1697533\n",
      "1153000 of 1697533\n",
      "1154000 of 1697533\n",
      "1155000 of 1697533\n",
      "1156000 of 1697533\n",
      "1157000 of 1697533\n",
      "1158000 of 1697533\n",
      "1159000 of 1697533\n",
      "1160000 of 1697533\n",
      "1161000 of 1697533\n",
      "1162000 of 1697533\n",
      "1163000 of 1697533\n",
      "1164000 of 1697533\n",
      "1165000 of 1697533\n",
      "1166000 of 1697533\n",
      "1167000 of 1697533\n",
      "1168000 of 1697533\n",
      "1169000 of 1697533\n",
      "1170000 of 1697533\n",
      "1171000 of 1697533\n",
      "1172000 of 1697533\n",
      "1173000 of 1697533\n",
      "1174000 of 1697533\n",
      "1175000 of 1697533\n",
      "1176000 of 1697533\n",
      "1177000 of 1697533\n",
      "1178000 of 1697533\n",
      "1179000 of 1697533\n",
      "1180000 of 1697533\n",
      "1181000 of 1697533\n",
      "1182000 of 1697533\n",
      "1183000 of 1697533\n",
      "1184000 of 1697533\n",
      "1185000 of 1697533\n",
      "1186000 of 1697533\n",
      "1187000 of 1697533\n",
      "1188000 of 1697533\n",
      "1189000 of 1697533\n",
      "1190000 of 1697533\n",
      "1191000 of 1697533\n",
      "1192000 of 1697533\n",
      "1193000 of 1697533\n",
      "1194000 of 1697533\n",
      "1195000 of 1697533\n",
      "1196000 of 1697533\n",
      "1197000 of 1697533\n",
      "1198000 of 1697533\n",
      "1199000 of 1697533\n",
      "1200000 of 1697533\n",
      "1201000 of 1697533\n",
      "1202000 of 1697533\n",
      "1203000 of 1697533\n",
      "1204000 of 1697533\n",
      "1205000 of 1697533\n",
      "1206000 of 1697533\n",
      "1207000 of 1697533\n",
      "1208000 of 1697533\n",
      "1209000 of 1697533\n",
      "1210000 of 1697533\n",
      "1211000 of 1697533\n",
      "1212000 of 1697533\n",
      "1213000 of 1697533\n",
      "1214000 of 1697533\n",
      "1215000 of 1697533\n",
      "1216000 of 1697533\n",
      "1217000 of 1697533\n",
      "1218000 of 1697533\n",
      "1219000 of 1697533\n",
      "1220000 of 1697533\n",
      "1221000 of 1697533\n",
      "1222000 of 1697533\n",
      "1223000 of 1697533\n",
      "1224000 of 1697533\n",
      "1225000 of 1697533\n",
      "1226000 of 1697533\n",
      "1227000 of 1697533\n",
      "1228000 of 1697533\n",
      "1229000 of 1697533\n",
      "1230000 of 1697533\n",
      "1231000 of 1697533\n",
      "1232000 of 1697533\n",
      "1233000 of 1697533\n",
      "1234000 of 1697533\n",
      "1235000 of 1697533\n",
      "1236000 of 1697533\n",
      "1237000 of 1697533\n",
      "1238000 of 1697533\n",
      "1239000 of 1697533\n",
      "1240000 of 1697533\n",
      "1241000 of 1697533\n",
      "1242000 of 1697533\n",
      "1243000 of 1697533\n",
      "1244000 of 1697533\n",
      "1245000 of 1697533\n",
      "1246000 of 1697533\n",
      "1247000 of 1697533\n",
      "1248000 of 1697533\n",
      "1249000 of 1697533\n",
      "1250000 of 1697533\n",
      "1251000 of 1697533\n",
      "1252000 of 1697533\n",
      "1253000 of 1697533\n",
      "1254000 of 1697533\n",
      "1255000 of 1697533\n",
      "1256000 of 1697533\n",
      "1257000 of 1697533\n",
      "1258000 of 1697533\n",
      "1259000 of 1697533\n",
      "1260000 of 1697533\n",
      "1261000 of 1697533\n",
      "1262000 of 1697533\n",
      "1263000 of 1697533\n",
      "1264000 of 1697533\n",
      "1265000 of 1697533\n",
      "1266000 of 1697533\n",
      "1267000 of 1697533\n",
      "1268000 of 1697533\n",
      "1269000 of 1697533\n",
      "1270000 of 1697533\n",
      "1271000 of 1697533\n",
      "1272000 of 1697533\n",
      "1273000 of 1697533\n",
      "1274000 of 1697533\n",
      "1275000 of 1697533\n",
      "1276000 of 1697533\n",
      "1277000 of 1697533\n",
      "1278000 of 1697533\n",
      "1279000 of 1697533\n",
      "1280000 of 1697533\n",
      "1281000 of 1697533\n",
      "1282000 of 1697533\n",
      "1283000 of 1697533\n",
      "1284000 of 1697533\n",
      "1285000 of 1697533\n",
      "1286000 of 1697533\n",
      "1287000 of 1697533\n",
      "1288000 of 1697533\n",
      "1289000 of 1697533\n",
      "1290000 of 1697533\n",
      "1291000 of 1697533\n",
      "1292000 of 1697533\n",
      "1293000 of 1697533\n",
      "1294000 of 1697533\n",
      "1295000 of 1697533\n",
      "1296000 of 1697533\n",
      "1297000 of 1697533\n",
      "1298000 of 1697533\n",
      "1299000 of 1697533\n",
      "1300000 of 1697533\n",
      "1301000 of 1697533\n",
      "1302000 of 1697533\n",
      "1303000 of 1697533\n",
      "1304000 of 1697533\n",
      "1305000 of 1697533\n",
      "1306000 of 1697533\n",
      "1307000 of 1697533\n",
      "1308000 of 1697533\n",
      "1309000 of 1697533\n",
      "1310000 of 1697533\n",
      "1311000 of 1697533\n",
      "1312000 of 1697533\n",
      "1313000 of 1697533\n",
      "1314000 of 1697533\n",
      "1315000 of 1697533\n",
      "1316000 of 1697533\n",
      "1317000 of 1697533\n",
      "1318000 of 1697533\n",
      "1319000 of 1697533\n",
      "1320000 of 1697533\n",
      "1321000 of 1697533\n",
      "1322000 of 1697533\n",
      "1323000 of 1697533\n",
      "1324000 of 1697533\n",
      "1325000 of 1697533\n",
      "1326000 of 1697533\n",
      "1327000 of 1697533\n",
      "1328000 of 1697533\n",
      "1329000 of 1697533\n",
      "1330000 of 1697533\n",
      "1331000 of 1697533\n",
      "1332000 of 1697533\n",
      "1333000 of 1697533\n",
      "1334000 of 1697533\n",
      "1335000 of 1697533\n",
      "1336000 of 1697533\n",
      "1337000 of 1697533\n",
      "1338000 of 1697533\n",
      "1339000 of 1697533\n",
      "1340000 of 1697533\n",
      "1341000 of 1697533\n",
      "1342000 of 1697533\n",
      "1343000 of 1697533\n",
      "1344000 of 1697533\n",
      "1345000 of 1697533\n",
      "1346000 of 1697533\n",
      "1347000 of 1697533\n",
      "1348000 of 1697533\n",
      "1349000 of 1697533\n",
      "1350000 of 1697533\n",
      "1351000 of 1697533\n",
      "1352000 of 1697533\n",
      "1353000 of 1697533\n",
      "1354000 of 1697533\n",
      "1355000 of 1697533\n",
      "1356000 of 1697533\n",
      "1357000 of 1697533\n",
      "1358000 of 1697533\n",
      "1359000 of 1697533\n",
      "1360000 of 1697533\n",
      "1361000 of 1697533\n",
      "1362000 of 1697533\n",
      "1363000 of 1697533\n",
      "1364000 of 1697533\n",
      "1365000 of 1697533\n",
      "1366000 of 1697533\n",
      "1367000 of 1697533\n",
      "1368000 of 1697533\n",
      "1369000 of 1697533\n",
      "1370000 of 1697533\n",
      "1371000 of 1697533\n",
      "1372000 of 1697533\n",
      "1373000 of 1697533\n",
      "1374000 of 1697533\n",
      "1375000 of 1697533\n",
      "1376000 of 1697533\n",
      "1377000 of 1697533\n",
      "1378000 of 1697533\n",
      "1379000 of 1697533\n",
      "1380000 of 1697533\n",
      "1381000 of 1697533\n",
      "1382000 of 1697533\n",
      "1383000 of 1697533\n",
      "1384000 of 1697533\n",
      "1385000 of 1697533\n",
      "1386000 of 1697533\n",
      "1387000 of 1697533\n",
      "1388000 of 1697533\n",
      "1389000 of 1697533\n",
      "1390000 of 1697533\n",
      "1391000 of 1697533\n",
      "1392000 of 1697533\n",
      "1393000 of 1697533\n",
      "1394000 of 1697533\n",
      "1395000 of 1697533\n",
      "1396000 of 1697533\n",
      "1397000 of 1697533\n",
      "1398000 of 1697533\n",
      "1399000 of 1697533\n",
      "1400000 of 1697533\n",
      "1401000 of 1697533\n",
      "1402000 of 1697533\n",
      "1403000 of 1697533\n",
      "1404000 of 1697533\n",
      "1405000 of 1697533\n",
      "1406000 of 1697533\n",
      "1407000 of 1697533\n",
      "1408000 of 1697533\n",
      "1409000 of 1697533\n",
      "1410000 of 1697533\n",
      "1411000 of 1697533\n",
      "1412000 of 1697533\n",
      "1413000 of 1697533\n",
      "1414000 of 1697533\n",
      "1415000 of 1697533\n",
      "1416000 of 1697533\n",
      "1417000 of 1697533\n",
      "1418000 of 1697533\n",
      "1419000 of 1697533\n",
      "1420000 of 1697533\n",
      "1421000 of 1697533\n",
      "1422000 of 1697533\n",
      "1423000 of 1697533\n",
      "1424000 of 1697533\n",
      "1425000 of 1697533\n",
      "1426000 of 1697533\n",
      "1427000 of 1697533\n",
      "1428000 of 1697533\n",
      "1429000 of 1697533\n",
      "1430000 of 1697533\n",
      "1431000 of 1697533\n",
      "1432000 of 1697533\n",
      "1433000 of 1697533\n",
      "1434000 of 1697533\n",
      "1435000 of 1697533\n",
      "1436000 of 1697533\n",
      "1437000 of 1697533\n",
      "1438000 of 1697533\n",
      "1439000 of 1697533\n",
      "1440000 of 1697533\n",
      "1441000 of 1697533\n",
      "1442000 of 1697533\n",
      "1443000 of 1697533\n",
      "1444000 of 1697533\n",
      "1445000 of 1697533\n",
      "1446000 of 1697533\n",
      "1447000 of 1697533\n",
      "1448000 of 1697533\n",
      "1449000 of 1697533\n",
      "1450000 of 1697533\n",
      "1451000 of 1697533\n",
      "1452000 of 1697533\n",
      "1453000 of 1697533\n",
      "1454000 of 1697533\n",
      "1455000 of 1697533\n",
      "1456000 of 1697533\n",
      "1457000 of 1697533\n",
      "1458000 of 1697533\n",
      "1459000 of 1697533\n",
      "1460000 of 1697533\n",
      "1461000 of 1697533\n",
      "1462000 of 1697533\n",
      "1463000 of 1697533\n",
      "1464000 of 1697533\n",
      "1465000 of 1697533\n",
      "1466000 of 1697533\n",
      "1467000 of 1697533\n",
      "1468000 of 1697533\n",
      "1469000 of 1697533\n",
      "1470000 of 1697533\n",
      "1471000 of 1697533\n",
      "1472000 of 1697533\n",
      "1473000 of 1697533\n",
      "1474000 of 1697533\n",
      "1475000 of 1697533\n",
      "1476000 of 1697533\n",
      "1477000 of 1697533\n",
      "1478000 of 1697533\n",
      "1479000 of 1697533\n",
      "1480000 of 1697533\n",
      "1481000 of 1697533\n",
      "1482000 of 1697533\n",
      "1483000 of 1697533\n",
      "1484000 of 1697533\n",
      "1485000 of 1697533\n",
      "1486000 of 1697533\n",
      "1487000 of 1697533\n",
      "1488000 of 1697533\n",
      "1489000 of 1697533\n",
      "1490000 of 1697533\n",
      "1491000 of 1697533\n",
      "1492000 of 1697533\n",
      "1493000 of 1697533\n",
      "1494000 of 1697533\n",
      "1495000 of 1697533\n",
      "1496000 of 1697533\n",
      "1497000 of 1697533\n",
      "1498000 of 1697533\n",
      "1499000 of 1697533\n",
      "1500000 of 1697533\n",
      "1501000 of 1697533\n",
      "1502000 of 1697533\n",
      "1503000 of 1697533\n",
      "1504000 of 1697533\n",
      "1505000 of 1697533\n",
      "1506000 of 1697533\n",
      "1507000 of 1697533\n",
      "1508000 of 1697533\n",
      "1509000 of 1697533\n",
      "1510000 of 1697533\n",
      "1511000 of 1697533\n",
      "1512000 of 1697533\n",
      "1513000 of 1697533\n",
      "1514000 of 1697533\n",
      "1515000 of 1697533\n",
      "1516000 of 1697533\n",
      "1517000 of 1697533\n",
      "1518000 of 1697533\n",
      "1519000 of 1697533\n",
      "1520000 of 1697533\n",
      "1521000 of 1697533\n",
      "1522000 of 1697533\n",
      "1523000 of 1697533\n",
      "1524000 of 1697533\n",
      "1525000 of 1697533\n",
      "1526000 of 1697533\n",
      "1527000 of 1697533\n",
      "1528000 of 1697533\n",
      "1529000 of 1697533\n",
      "1530000 of 1697533\n",
      "1531000 of 1697533\n",
      "1532000 of 1697533\n",
      "1533000 of 1697533\n",
      "1534000 of 1697533\n",
      "1535000 of 1697533\n",
      "1536000 of 1697533\n",
      "1537000 of 1697533\n",
      "1538000 of 1697533\n",
      "1539000 of 1697533\n",
      "1540000 of 1697533\n",
      "1541000 of 1697533\n",
      "1542000 of 1697533\n",
      "1543000 of 1697533\n",
      "1544000 of 1697533\n",
      "1545000 of 1697533\n",
      "1546000 of 1697533\n",
      "1547000 of 1697533\n",
      "1548000 of 1697533\n",
      "1549000 of 1697533\n",
      "1550000 of 1697533\n",
      "1551000 of 1697533\n",
      "1552000 of 1697533\n",
      "1553000 of 1697533\n",
      "1554000 of 1697533\n",
      "1555000 of 1697533\n",
      "1556000 of 1697533\n",
      "1557000 of 1697533\n",
      "1558000 of 1697533\n",
      "1559000 of 1697533\n",
      "1560000 of 1697533\n",
      "1561000 of 1697533\n",
      "1562000 of 1697533\n",
      "1563000 of 1697533\n",
      "1564000 of 1697533\n",
      "1565000 of 1697533\n",
      "1566000 of 1697533\n",
      "1567000 of 1697533\n",
      "1568000 of 1697533\n",
      "1569000 of 1697533\n",
      "1570000 of 1697533\n",
      "1571000 of 1697533\n",
      "1572000 of 1697533\n",
      "1573000 of 1697533\n",
      "1574000 of 1697533\n",
      "1575000 of 1697533\n",
      "1576000 of 1697533\n",
      "1577000 of 1697533\n",
      "1578000 of 1697533\n",
      "1579000 of 1697533\n",
      "1580000 of 1697533\n",
      "1581000 of 1697533\n",
      "1582000 of 1697533\n",
      "1583000 of 1697533\n",
      "1584000 of 1697533\n",
      "1585000 of 1697533\n",
      "1586000 of 1697533\n",
      "1587000 of 1697533\n",
      "1588000 of 1697533\n",
      "1589000 of 1697533\n",
      "1590000 of 1697533\n",
      "1591000 of 1697533\n",
      "1592000 of 1697533\n",
      "1593000 of 1697533\n",
      "1594000 of 1697533\n",
      "1595000 of 1697533\n",
      "1596000 of 1697533\n",
      "1597000 of 1697533\n",
      "1598000 of 1697533\n",
      "1599000 of 1697533\n",
      "1600000 of 1697533\n",
      "1601000 of 1697533\n",
      "1602000 of 1697533\n",
      "1603000 of 1697533\n",
      "1604000 of 1697533\n",
      "1605000 of 1697533\n",
      "1606000 of 1697533\n",
      "1607000 of 1697533\n",
      "1608000 of 1697533\n",
      "1609000 of 1697533\n",
      "1610000 of 1697533\n",
      "1611000 of 1697533\n",
      "1612000 of 1697533\n",
      "1613000 of 1697533\n",
      "1614000 of 1697533\n",
      "1615000 of 1697533\n",
      "1616000 of 1697533\n",
      "1617000 of 1697533\n",
      "1618000 of 1697533\n",
      "1619000 of 1697533\n",
      "1620000 of 1697533\n",
      "1621000 of 1697533\n",
      "1622000 of 1697533\n",
      "1623000 of 1697533\n",
      "1624000 of 1697533\n",
      "1625000 of 1697533\n",
      "1626000 of 1697533\n",
      "1627000 of 1697533\n",
      "1628000 of 1697533\n",
      "1629000 of 1697533\n",
      "1630000 of 1697533\n",
      "1631000 of 1697533\n",
      "1632000 of 1697533\n",
      "1633000 of 1697533\n",
      "1634000 of 1697533\n",
      "1635000 of 1697533\n",
      "1636000 of 1697533\n",
      "1637000 of 1697533\n",
      "1638000 of 1697533\n",
      "1639000 of 1697533\n",
      "1640000 of 1697533\n",
      "1641000 of 1697533\n",
      "1642000 of 1697533\n",
      "1643000 of 1697533\n",
      "1644000 of 1697533\n",
      "1645000 of 1697533\n",
      "1646000 of 1697533\n",
      "1647000 of 1697533\n",
      "1648000 of 1697533\n",
      "1649000 of 1697533\n",
      "1650000 of 1697533\n",
      "1651000 of 1697533\n",
      "1652000 of 1697533\n",
      "1653000 of 1697533\n",
      "1654000 of 1697533\n",
      "1655000 of 1697533\n",
      "1656000 of 1697533\n",
      "1657000 of 1697533\n",
      "1658000 of 1697533\n",
      "1659000 of 1697533\n",
      "1660000 of 1697533\n",
      "1661000 of 1697533\n",
      "1662000 of 1697533\n",
      "1663000 of 1697533\n",
      "1664000 of 1697533\n",
      "1665000 of 1697533\n",
      "1666000 of 1697533\n",
      "1667000 of 1697533\n",
      "1668000 of 1697533\n",
      "1669000 of 1697533\n",
      "1670000 of 1697533\n",
      "1671000 of 1697533\n",
      "1672000 of 1697533\n",
      "1673000 of 1697533\n",
      "1674000 of 1697533\n",
      "1675000 of 1697533\n",
      "1676000 of 1697533\n",
      "1677000 of 1697533\n",
      "1678000 of 1697533\n",
      "1679000 of 1697533\n",
      "1680000 of 1697533\n",
      "1681000 of 1697533\n",
      "1682000 of 1697533\n",
      "1683000 of 1697533\n",
      "1684000 of 1697533\n",
      "1685000 of 1697533\n",
      "1686000 of 1697533\n",
      "1687000 of 1697533\n",
      "1688000 of 1697533\n",
      "1689000 of 1697533\n",
      "1690000 of 1697533\n",
      "1691000 of 1697533\n",
      "1692000 of 1697533\n",
      "1693000 of 1697533\n",
      "1694000 of 1697533\n",
      "1695000 of 1697533\n",
      "1696000 of 1697533\n",
      "1697000 of 1697533\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "with open('labeled_reviews.txt', 'w') as f:  \n",
    "    ## we need to make a dataset for fasttext\n",
    "    for idx, row in df.iterrows():\n",
    "        ## make sure there are no pesky new line characters\n",
    "        review = row['reviewText'].replace(\"\\n\", \" \")\n",
    "        rating = \"__label__\" + str(row['overall'])[0]\n",
    "        f.write(rating)\n",
    "        f.write(\" \")\n",
    "        f.write(review)\n",
    "        f.write(\"\\n\")\n",
    "        counter += 1\n",
    "        if (counter % 10000 == 0):\n",
    "            print(counter, \"of\", nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "so we are using the default fasttext learning model (which is what? a neural net?), with 5 epochs, using an 80/20 training split. we have it set to just \"unigrams\" which is to say that its not \"learning\" bigrams -- need to look into this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Model (attempt 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> fasttext supervised -input movies.train -output model_movies\n",
    "Read 236M words\n",
    "Number of words:  4636911\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1993901  lr: 0.000000  loss: 0.853279  eta: 0h0m "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> fasttext test model_movies.bin movies.valid \n",
    "N\t339507\n",
    "P@1\t0.639\n",
    "R@1\t0.639\n",
    "Number of examples: 339507\n",
    "\n",
    "so, on average, the model's top guess for the label is right 64% of the time. not great!\n",
    "\n",
    "this is the most naiive model. lets see if more epochs helps at all ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats\n",
    "__label__4\n",
    "i loved this moview\n",
    "__label__5\n",
    "i hated this movie \n",
    "__label__1\n",
    "movies like this are great\n",
    "__label__5\n",
    "movies like this are terrible\n",
    "__label__1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if these \"easy\" changes dont really increase accuracy that much, we should do the \"hard\" analysis and actually see where our model is doing well and where it is doing poorly and try to gain some insight"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fasttext supervised -input movies.train -output model_movies -epoch 20\n",
    "Read 236M words\n",
    "Number of words:  4636911\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1949821  lr: 0.000000  loss: 0.820269  eta: 0h0m "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "it overfit!\n",
    "\n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> fasttext test model_movies.bin movies.valid \n",
    "N\t339507\n",
    "P@1\t0.629\n",
    "R@1\t0.629\n",
    "Number of examples: 339507\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "so clearly just increasing the number of epochs from 5 to 20 didnt do much. in fact, it looks like the model slightly overfit, since accuracy went down a tad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now im trying to preprocess the text first, the idea being 1) the vocabulary will be smaller, which might a) be fewer params for the model to learn (still have to read the paper) and b) the same word that appears with a period or in uppercase (for example at the beg of a sentence) will not be the same entity, so whatever contexts have been learned for them will be merged, so perhaps the sharing of that information will make the model more precise on that one entity now than before, i.e. it has more contexts, might be better able to generalize, etc ... \n",
    "\n",
    "cat labeled_reviews.txt | sed -e \"s/([.!?,'/()])/ 1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > movies.preprocessed.txt\n",
    "\n",
    "using bash to process data is cool!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fasttext supervised -input movies.preprocessed.train -output model.movies\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 2099022  lr: 0.000000  loss: 0.862818  eta: 0h0m\n",
    "\n",
    "as you can see the number of unique words dropped by about 500k, from 4.6million to 4.1million"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "well it didnt help!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> fasttext test model.movies.bin movies.preprocessed.valid  \n",
    "N\t339507\n",
    "P@1\t0.638\n",
    "R@1\t0.638\n",
    "Number of examples: 339507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ok so it budged when i made it consider bigrams\n",
    "\n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> fasttext test model.movies.bin movies.preprocessed.valid  \n",
    "N\t339507\n",
    "P@1\t0.659\n",
    "R@1\t0.659\n",
    "Number of examples: 339507"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with trigrams i think it will be even better, check out the training loss\n",
    "\n",
    "fasttext supervised -input movies.preprocessed.train -output model.movies -wordNgrams 3\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 650334  lr: 0.000000  loss: 0.618070  eta: 0h0m \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "actually not really!\n",
    "    \n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> fasttext test model.movies.bin movies.preprocessed.valid  \n",
    "N\t339507\n",
    "P@1\t0.655\n",
    "R@1\t0.655\n",
    "Number of examples: 339507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interestingly, a lower learning rate always improved the precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> ./test.sh \n",
    "BEGIN\n",
    "0.1\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1064823  lr: 0.000000  loss: 0.772600  eta: 0h0m m \n",
    "N\t339507\n",
    "P@1\t0.659\n",
    "R@1\t0.659\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.2\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1042450  lr: 0.000000  loss: 0.760522  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.653\n",
    "R@1\t0.653\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.3\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1024664  lr: 0.000000  loss: 0.755202  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.651\n",
    "R@1\t0.651\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.4\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1043209  lr: 0.000000  loss: 0.755358  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.651\n",
    "R@1\t0.651\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.5\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1022692  lr: 0.000000  loss: 0.753736  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.649\n",
    "R@1\t0.649\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.6\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1084230  lr: 0.000000  loss: 0.818311  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.649\n",
    "R@1\t0.649\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.7\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1076990  lr: 0.000000  loss: 0.755232  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.646\n",
    "R@1\t0.646\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.8\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1097927  lr: 0.000000  loss: 0.700342  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.644\n",
    "R@1\t0.644\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.9\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1083960  lr: 0.000000  loss: 0.704557  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.644\n",
    "R@1\t0.644\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "1.0\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1067443  lr: 0.000000  loss: 0.715676  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.643\n",
    "R@1\t0.643\n",
    "Number of examples: 339507"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finally got to about 0.661, after doing a search over learning rate and num epochs, landed on an alpha of 0.04, and num epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEGIN\n",
    "0.1\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1064823  lr: 0.000000  loss: 0.772600  eta: 0h0m m \n",
    "N\t339507\n",
    "P@1\t0.659\n",
    "R@1\t0.659\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.2\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1042450  lr: 0.000000  loss: 0.760522  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.653\n",
    "R@1\t0.653\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.3\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1024664  lr: 0.000000  loss: 0.755202  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.651\n",
    "R@1\t0.651\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.4\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1043209  lr: 0.000000  loss: 0.755358  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.651\n",
    "R@1\t0.651\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.5\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1022692  lr: 0.000000  loss: 0.753736  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.649\n",
    "R@1\t0.649\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.6\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1084230  lr: 0.000000  loss: 0.818311  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.649\n",
    "R@1\t0.649\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.7\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1076990  lr: 0.000000  loss: 0.755232  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.646\n",
    "R@1\t0.646\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.8\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1097927  lr: 0.000000  loss: 0.700342  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.644\n",
    "R@1\t0.644\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "0.9\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1083960  lr: 0.000000  loss: 0.704557  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.644\n",
    "R@1\t0.644\n",
    "Number of examples: 339507\n",
    "\n",
    "BEGIN\n",
    "1.0\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1067443  lr: 0.000000  loss: 0.715676  eta: 0h0m \n",
    "N\t339507\n",
    "P@1\t0.643\n",
    "R@1\t0.643\n",
    "Number of examples: 339507\n",
    "\n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> vi test.sh\n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> ./test.sh > testing_epochs_and_learning_rate\n",
    "./test.sh: line 14: syntax error: unexpected end of file\n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> ./test.sh\n",
    "./test.sh: line 14: syntax error: unexpected end of file\n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> vi test.sh\n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> ./test.sh > testing_epochs_and_learning_rate\n",
    "Read 236M words^[^[\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1060920  lr: 0.000000  loss: 0.894319  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1046925  lr: 0.000000  loss: 0.883131  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1063102  lr: 0.000000  loss: 0.765177  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1076385  lr: 0.000000  loss: 0.771816  eta: 0h0m 4m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1068624  lr: 0.000000  loss: 0.666950  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1057871  lr: 0.000000  loss: 0.547344  eta: 0h0m m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1073525  lr: 0.000000  loss: 0.763699  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1064129  lr: 0.000000  loss: 0.688292  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1056036  lr: 0.000000  loss: 0.533205  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1077244  lr: 0.000000  loss: 0.732160  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1066405  lr: 0.000000  loss: 0.628854  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1059979  lr: 0.000000  loss: 0.525804  eta: 0h0m m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1074174  lr: 0.000000  loss: 0.758102  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1063802  lr: 0.000000  loss: 0.666267  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "Read 236M words\n",
    "Number of words:  4167627\n",
    "Number of labels: 5\n",
    "Progress: 100.0%  words/sec/thread: 1060916  lr: 0.000000  loss: 0.503459  eta: 0h0m \n",
    "Number of examples: 339507\n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> less testing_epochs_and_learning_rate \n",
    "joshuamalina@Joshuas-MacBook-Pro-2 ~/d/movies> less testing_epochs_and_learning_rate \n",
    "\n",
    "BEGIN\n",
    "learning rate 0.01\n",
    "num epochs 5\n",
    "N       339507\n",
    "P@1     0.637\n",
    "R@1     0.637\n",
    "\n",
    "BEGIN\n",
    "learning rate 0.01\n",
    "num epochs 10\n",
    "N       339507\n",
    "P@1     0.655\n",
    "R@1     0.655\n",
    "\n",
    "BEGIN\n",
    "learning rate 0.01\n",
    "num epochs 15\n",
    "N       339507\n",
    "P@1     0.66\n",
    "R@1     0.66\n",
    "\n",
    "BEGIN\n",
    "learning rate 0.04\n",
    "num epochs 5\n",
    "N       339507\n",
    "P@1     0.661\n",
    "R@1     0.661\n",
    "\n",
    "BEGIN\n",
    "learning rate 0.04\n",
    "num epochs 10\n",
    "N       339507\n",
    "P@1     0.655\n",
    "R@1     0.655\n",
    "testing_epochs_and_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "might want to try increasing the dimensionality of the word / sentence vectors\n",
    "\n",
    "we really need to look at the distribution of errors. what are they incorrectly predicting and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "fastText: Cannot load model.movies.bin due to C++ extension failed to allocate the memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32mfasttext/fasttext.pyx\u001b[0m in \u001b[0;36mfasttext.fasttext.load_model (fasttext/fasttext.cpp:3833)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: vector",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-255768cbd29e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.movies.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mfasttext/fasttext.pyx\u001b[0m in \u001b[0;36mfasttext.fasttext.load_model (fasttext/fasttext.cpp:3891)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: fastText: Cannot load model.movies.bin due to C++ extension failed to allocate the memory"
     ]
    }
   ],
   "source": [
    "fasttext.load_model('model.movies.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.supervised(input_file='movies.preprocessed.train', \\\n",
    "                    output='model_lr_04_epoch_5_ngrams_3_emb_300', \\\n",
    "                    dim=300, \\\n",
    "                    word_ngrams=3, \n",
    "                    epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = []\n",
    "with open('review_vectors.txt', 'r') as f:\n",
    "    with open('review_vectors_clean', 'w') as ff:\n",
    "        ls = f.readlines()\n",
    "        for l in ls:\n",
    "            parts = l.split(' ')\n",
    "            vec = parts[-101:-1]\n",
    "            vec = list(map(lambda x: float(x), vec))\n",
    "            vecs.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016051 0.12057 -0.06737 0.0043932 0.11127 -0.010199 -0.015874 0.040441 0.026757 0.078335 0.018461 0.022986 -0.0070111 0.080225 0.047282 -0.060775 0.036818 -0.0040064 0.048193 0.056838 -0.10669 -0.044939 0.016606 -0.037385 -0.069062 0.026022 0.096197 -0.036572 0.0060092 -0.010497 -0.038409 9.6061e-05 0.03998 0.016378 0.03852 0.011253 -0.020887 -0.065213 0.060221 0.11804 0.055575 0.080329 -0.067539 0.063979 -0.067433 -0.050932 0.0060643 0.083539 0.051772 0.10461 -0.05688 -0.0033336 -0.080524 0.057396 -0.068557 -0.049274 -0.036987 -0.077541 0.045895 0.057291 0.0038837 -0.0090696 0.17137 -0.086732 -0.029844 0.053889 0.010123 -0.0057181 -0.10259 -0.012729 -0.077592 -0.036338 0.20425 -0.070563 -0.10558 0.037965 -0.030828 -0.048266 0.083954 0.061895 -0.090573 0.062647 -0.00096994 -0.11337 -0.076072 0.10858 -0.11236 -0.10825 0.0045284 0.043185 -0.18823 0.032295 0.072339 -0.053426 -0.16778 0.0094829 -0.083266 0.039626 -0.047427 -0.051245 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('review_vectors_clean', 'r') as f:\n",
    "    l = f.readline()\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=vecs, y=truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuamalina/tools/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vecs[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_model.Lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = df.overall.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1697533,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmd=\"ls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = subprocess.Popen(cmd, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
